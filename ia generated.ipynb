{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d10af997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "391/391 [==============================] - 8s 16ms/step - loss: 1.3764 - accuracy: 0.5230 - val_loss: 1.2446 - val_accuracy: 0.5662\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1.1816 - accuracy: 0.5897 - val_loss: 1.1879 - val_accuracy: 0.5870\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1.1172 - accuracy: 0.6108 - val_loss: 1.1618 - val_accuracy: 0.5950\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1.0692 - accuracy: 0.6278 - val_loss: 1.1452 - val_accuracy: 0.5999\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 1.0286 - accuracy: 0.6400 - val_loss: 1.1233 - val_accuracy: 0.6096\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.9902 - accuracy: 0.6520 - val_loss: 1.1072 - val_accuracy: 0.6133\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.9558 - accuracy: 0.6651 - val_loss: 1.1003 - val_accuracy: 0.6173\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.9253 - accuracy: 0.6772 - val_loss: 1.0955 - val_accuracy: 0.6202\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.8920 - accuracy: 0.6876 - val_loss: 1.0913 - val_accuracy: 0.6251\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.8611 - accuracy: 0.7010 - val_loss: 1.1109 - val_accuracy: 0.6157\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.8324 - accuracy: 0.7087 - val_loss: 1.0933 - val_accuracy: 0.6229\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.8050 - accuracy: 0.7216 - val_loss: 1.1007 - val_accuracy: 0.6266\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.7764 - accuracy: 0.7304 - val_loss: 1.1166 - val_accuracy: 0.6189\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.7515 - accuracy: 0.7392 - val_loss: 1.1058 - val_accuracy: 0.6278\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.7259 - accuracy: 0.7480 - val_loss: 1.1239 - val_accuracy: 0.6248\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.6981 - accuracy: 0.7588 - val_loss: 1.1417 - val_accuracy: 0.6214\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.6751 - accuracy: 0.7681 - val_loss: 1.1380 - val_accuracy: 0.6257\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.6508 - accuracy: 0.7759 - val_loss: 1.1599 - val_accuracy: 0.6219\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.6288 - accuracy: 0.7832 - val_loss: 1.1876 - val_accuracy: 0.6163\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.6036 - accuracy: 0.7940 - val_loss: 1.1757 - val_accuracy: 0.6235\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.5823 - accuracy: 0.8021 - val_loss: 1.1736 - val_accuracy: 0.6224\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.5593 - accuracy: 0.8108 - val_loss: 1.1914 - val_accuracy: 0.6191\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.5417 - accuracy: 0.8159 - val_loss: 1.2304 - val_accuracy: 0.6158\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.5207 - accuracy: 0.8256 - val_loss: 1.2217 - val_accuracy: 0.6221\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.4975 - accuracy: 0.8315 - val_loss: 1.2334 - val_accuracy: 0.6236\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 0.4787 - accuracy: 0.8409 - val_loss: 1.2507 - val_accuracy: 0.6222\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.4587 - accuracy: 0.8474 - val_loss: 1.2691 - val_accuracy: 0.6231\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.4408 - accuracy: 0.8550 - val_loss: 1.3001 - val_accuracy: 0.6193\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.4223 - accuracy: 0.8618 - val_loss: 1.3266 - val_accuracy: 0.6173\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.4087 - accuracy: 0.8663 - val_loss: 1.3666 - val_accuracy: 0.6147\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.3934 - accuracy: 0.8705 - val_loss: 1.3602 - val_accuracy: 0.6173\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 0.3711 - accuracy: 0.8802 - val_loss: 1.3797 - val_accuracy: 0.6135\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 0.3560 - accuracy: 0.8864 - val_loss: 1.4210 - val_accuracy: 0.6147\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 0.3394 - accuracy: 0.8913 - val_loss: 1.4358 - val_accuracy: 0.6166\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 0.3267 - accuracy: 0.8976 - val_loss: 1.4345 - val_accuracy: 0.6177\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 0.3120 - accuracy: 0.9031 - val_loss: 1.4672 - val_accuracy: 0.6157\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 0.2990 - accuracy: 0.9062 - val_loss: 1.5013 - val_accuracy: 0.6192\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 0.2868 - accuracy: 0.9117 - val_loss: 1.5616 - val_accuracy: 0.6032\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 0.2741 - accuracy: 0.9162 - val_loss: 1.5635 - val_accuracy: 0.6082\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.2561 - accuracy: 0.9222 - val_loss: 1.5904 - val_accuracy: 0.6098\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.2478 - accuracy: 0.9262 - val_loss: 1.6135 - val_accuracy: 0.6078\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.2379 - accuracy: 0.9283 - val_loss: 1.6207 - val_accuracy: 0.6173\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.2227 - accuracy: 0.9349 - val_loss: 1.6474 - val_accuracy: 0.6119\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.2127 - accuracy: 0.9386 - val_loss: 1.6752 - val_accuracy: 0.6120\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.2038 - accuracy: 0.9399 - val_loss: 1.7022 - val_accuracy: 0.6102\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 0.1918 - accuracy: 0.9452 - val_loss: 1.7420 - val_accuracy: 0.6039\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 0.1862 - accuracy: 0.9458 - val_loss: 1.7729 - val_accuracy: 0.6066\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 0.1793 - accuracy: 0.9487 - val_loss: 1.8361 - val_accuracy: 0.5991\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 0.1693 - accuracy: 0.9523 - val_loss: 1.8224 - val_accuracy: 0.6082\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.1602 - accuracy: 0.9560 - val_loss: 1.8432 - val_accuracy: 0.5991\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.1490 - accuracy: 0.9605 - val_loss: 1.8910 - val_accuracy: 0.6032\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.1428 - accuracy: 0.9626 - val_loss: 1.9309 - val_accuracy: 0.6010\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.1413 - accuracy: 0.9615 - val_loss: 1.9497 - val_accuracy: 0.6076\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.1291 - accuracy: 0.9675 - val_loss: 1.9866 - val_accuracy: 0.6048\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.1212 - accuracy: 0.9698 - val_loss: 2.0277 - val_accuracy: 0.5984\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.1184 - accuracy: 0.9704 - val_loss: 2.0577 - val_accuracy: 0.5963\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.1140 - accuracy: 0.9712 - val_loss: 2.0678 - val_accuracy: 0.6010\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.1134 - accuracy: 0.9708 - val_loss: 2.1432 - val_accuracy: 0.5987\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0979 - accuracy: 0.9780 - val_loss: 2.1382 - val_accuracy: 0.6009\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0936 - accuracy: 0.9787 - val_loss: 2.2071 - val_accuracy: 0.6006\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0946 - accuracy: 0.9770 - val_loss: 2.2339 - val_accuracy: 0.5923\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0851 - accuracy: 0.9810 - val_loss: 2.2799 - val_accuracy: 0.5959\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0817 - accuracy: 0.9819 - val_loss: 2.2959 - val_accuracy: 0.5993\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0852 - accuracy: 0.9797 - val_loss: 2.3094 - val_accuracy: 0.6002\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0750 - accuracy: 0.9839 - val_loss: 2.3018 - val_accuracy: 0.6028\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0721 - accuracy: 0.9844 - val_loss: 2.3674 - val_accuracy: 0.6042\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0661 - accuracy: 0.9866 - val_loss: 2.3862 - val_accuracy: 0.5960\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0724 - accuracy: 0.9833 - val_loss: 2.4509 - val_accuracy: 0.5970\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0647 - accuracy: 0.9861 - val_loss: 2.5240 - val_accuracy: 0.5994\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0591 - accuracy: 0.9889 - val_loss: 2.4755 - val_accuracy: 0.6023\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0542 - accuracy: 0.9896 - val_loss: 2.5003 - val_accuracy: 0.5976\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0604 - accuracy: 0.9868 - val_loss: 2.5385 - val_accuracy: 0.5982\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0532 - accuracy: 0.9895 - val_loss: 2.5733 - val_accuracy: 0.5946\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0442 - accuracy: 0.9930 - val_loss: 2.6027 - val_accuracy: 0.5956\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0636 - accuracy: 0.9838 - val_loss: 2.6847 - val_accuracy: 0.5954\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0425 - accuracy: 0.9926 - val_loss: 2.6727 - val_accuracy: 0.5988\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0354 - accuracy: 0.9952 - val_loss: 2.6865 - val_accuracy: 0.6011\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0498 - accuracy: 0.9889 - val_loss: 2.8231 - val_accuracy: 0.5841\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0705 - accuracy: 0.9791 - val_loss: 2.7393 - val_accuracy: 0.5935\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0438 - accuracy: 0.9908 - val_loss: 2.7622 - val_accuracy: 0.5965\n",
      "Epoch 81/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0278 - accuracy: 0.9971 - val_loss: 2.7749 - val_accuracy: 0.5990\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0265 - accuracy: 0.9968 - val_loss: 2.8169 - val_accuracy: 0.5993\n",
      "Epoch 83/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0410 - accuracy: 0.9910 - val_loss: 2.8807 - val_accuracy: 0.5892\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0698 - accuracy: 0.9795 - val_loss: 2.8867 - val_accuracy: 0.5962\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0290 - accuracy: 0.9955 - val_loss: 2.8523 - val_accuracy: 0.5994\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0222 - accuracy: 0.9974 - val_loss: 2.8922 - val_accuracy: 0.6002\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0170 - accuracy: 0.9991 - val_loss: 2.9309 - val_accuracy: 0.5957\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0164 - accuracy: 0.9988 - val_loss: 2.9746 - val_accuracy: 0.5916\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.1346 - accuracy: 0.9525 - val_loss: 3.0634 - val_accuracy: 0.5899\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0290 - accuracy: 0.9952 - val_loss: 2.9470 - val_accuracy: 0.5991\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0121 - accuracy: 0.9996 - val_loss: 2.9651 - val_accuracy: 0.5988\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0104 - accuracy: 0.9998 - val_loss: 2.9780 - val_accuracy: 0.6025\n",
      "Epoch 93/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0098 - accuracy: 0.9998 - val_loss: 2.9989 - val_accuracy: 0.5996\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0259 - accuracy: 0.9936 - val_loss: 3.2336 - val_accuracy: 0.5829\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.1123 - accuracy: 0.9611 - val_loss: 3.0932 - val_accuracy: 0.5932\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0165 - accuracy: 0.9987 - val_loss: 3.0560 - val_accuracy: 0.5971\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 3.0712 - val_accuracy: 0.6018\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0093 - accuracy: 0.9996 - val_loss: 3.0873 - val_accuracy: 0.5999\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0084 - accuracy: 0.9999 - val_loss: 3.1099 - val_accuracy: 0.6024\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.0302 - accuracy: 0.9919 - val_loss: 3.6066 - val_accuracy: 0.5640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b254752f80>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# load the CIFAR 10 dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# preprocess the data by scaling it to the range [0, 1]\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# convert the labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# load the VGG16 model pre-trained on ImageNet\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# add a fully-connected layer\n",
    "x = Dense(512, activation='relu')(x)\n",
    "\n",
    "# add a logistic layer with 10 classes\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# create a model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=100, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b383ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 3.6066 - accuracy: 0.5640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.606555938720703, 0.5640000104904175]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4c33dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,982,474\n",
      "Trainable params: 267,786\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddedeb88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
